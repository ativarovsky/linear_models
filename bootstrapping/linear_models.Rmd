---
title: "Bootstrapping"
author: "Alice Tivarovsky"
date: "11/14/2019"
output: github_document
editor_options: 
  chunk_output_type: console
---

# Slides 

Bootsrapping = repeated sampling but from the same sample. 

# Examples

Setup code

```{r setup}

library(tidyverse)
library(p8105.datasets)

set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))

```


## Bootstrapping in SLR
 

```{r}
n_samp = 250

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)
```


```{r}
sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "data_source") 

sim_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  facet_grid(~data_source) 
```

These datasets have roughly the same overall variance, but the left panel shows data with constant variance and the right panel shows data with non-constant variance. For this reason, ordinary least squares should provide reasonable estimates in both cases, but inference is standard inference approaches may only be justified for the data on the left.

```{r}
lm(y ~ x, data = sim_df_const) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

lm(y ~ x, data = sim_df_nonconst) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

## How to bootstrap

Write a fucntion to draw a bootstrap sample based on a dataframe. 

```{r}
sim_df_nonconst %>% 
  sample_frac(size = 1, replace = TRUE) %>% 
  arrange(x)
```

Write a function to do this a bunch of times. 

```{r}
boot_sample = function(x){
  sample_frac(sim_df, replace = TRUE)
}
```

```{r}
boot_sample(sim_df_nonconst) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm")
```


## Drawing many bootstrap samples 

Organize a dataframe: 

```{r}
boot_straps = 
  tibble(
    strap_number = 1:1000,
    strap_sample = rerun(1000, boot_sample(sim_df_nonconst))
  )
```


What is the distribution of the slope in these samples? 

```{r}
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(y ~ x, data = .x)), #fitting
    results = map(models, broom::tidy) # extracting
  ) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

```

summarize these results: 

## Try the modelr package 

```{r}
boot_straps = 
  sim_df_nonconst %>% 
  modelr::bootstrap(n = 1000)
```

## What if your assumptions aren't wrong? 

```{r}
sim_df_const %>% 
  lm(y ~x, data = .) %>% 
  broom::tidy()
```

## Airbnb Example 

```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(stars = review_scores_location / 2) %>% 
  rename(
    boro = neighbourhood_group,
    neighborhood = neighbourhood) %>% 
  filter(boro != "Staten Island") %>% 
  select(price, stars, boro, neighborhood, room_type)
```


```{r}
nyc_airbnb %>% 
  ggplot(aes(x = stars, y = price, color = room_type)) + 
  geom_point() 
```

Re-use stuff up top...

```{r}
nyc_airbnb %>% 
  filter(boro == "Manhattan") %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~ lm(price ~ stars + room_type, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(results) %>% 
  unnest(results) %>% 
  filter(term == "stars") %>% 
  ggplot(aes(x = estimate)) + geom_density()
```

Note that this is not a normal distribution - it's skewed. This is an example of when violations of assumptions give you results that don't make sense. 


# Other Materials

* This
* and that